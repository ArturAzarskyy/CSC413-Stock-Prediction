{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArturAzarskyy/CSC413-Stock-Prediction/blob/main/transformer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer model for Stock prediction"
      ],
      "metadata": {
        "id": "9pLJEKQAho8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparations:\n",
        "\n",
        "Note that torch dataset  and sampler were inspired from `yousefnami`'s article about\n",
        "[Reading .h5 Files Faster with PyTorch Datasets](https://towardsdatascience.com/reading-h5-files-faster-with-pytorch-datasets-3ff86938cc)"
      ],
      "metadata": {
        "id": "JjaPnVGE9pSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the pre-processed data from the "
      ],
      "metadata": {
        "id": "SlAbOtnh1p-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/amd/')"
      ],
      "metadata": {
        "id": "EunBcf6jhomO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9784c3de-ac7b-44f8-fc34-f0f585106fe4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /amd/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_mvg_avg_f = False"
      ],
      "metadata": {
        "id": "Kq3zQAVM2S04"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if load_mvg_avg_f:\n",
        "    !cp /amd/My\\ Drive/CSC413/Data/sp_data_orig_m_avg.zip /content/\n",
        "    !unzip sp_data_orig.zip\n",
        "else:\n",
        "    !cp /amd/My\\ Drive/CSC413/Data/sp_data_orig.zip /content/\n",
        "    !unzip sp_data_orig.zip"
      ],
      "metadata": {
        "id": "YoOJi5YUjUbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be66a44f-dadf-4c4c-9b81-b603160cb1d4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sp_data_orig.zip\n",
            "  inflating: test_data.hdf5          \n",
            "  inflating: train_data.hdf5         \n",
            "  inflating: val_data.hdf5           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "oVRXRA0EOSAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yEFAqEAX_5S3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler\n",
        "from torchvision.transforms import Compose\n",
        "import tables\n",
        "import torch as ty\n",
        "import torch.nn as nn\n",
        "import os.path\n",
        "import numpy as np\n",
        "import time\n",
        "seq_len = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a custom dataset for pytorch"
      ],
      "metadata": {
        "id": "sn4tkdqM1ep4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self, file_name, shuffle=True):\n",
        "        super(StockDataset, self).__init__()\n",
        "        hdf5_file = tables.open_file(file_name, mode='r')\n",
        "        assert('data' in hdf5_file.root)\n",
        "        assert('labels' in hdf5_file.root)\n",
        "        self.f_name = file_name\n",
        "        self.data = hdf5_file.root.data\n",
        "        self.lables = hdf5_file.root.labels\n",
        "        self.size = self.data.shape[0]\n",
        "        self.shuffle = shuffle\n",
        "        self.trans_data = Compose([self._from_numpy])\n",
        "        self.trans_labels = Compose([self._from_numpy, self._prepare_class_task])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # print('here', index)\n",
        "        X = np.array(self.data[index, :])\n",
        "        y = np.array(self.lables[index])\n",
        "        if self.shuffle and type(index) == list:\n",
        "            permute = ty.randperm(len(index))\n",
        "            X = X[permute, :]\n",
        "            y = y[permute]\n",
        "            y = self.trans_labels(y)\n",
        "        else:\n",
        "            y = self.trans_data(y)\n",
        "        X = self.trans_data(X)\n",
        "        return X, y\n",
        "\n",
        "    def _prepare_class_task(self, tensor):\n",
        "        return ty.reshape(tensor, (-1,))\n",
        "\n",
        "    def _from_numpy(self, tensor):\n",
        "        return ty.from_numpy(tensor).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size"
      ],
      "metadata": {
        "id": "lFk9Zq402m1U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creaiting samplers and two ways of sampling"
      ],
      "metadata": {
        "id": "lew5NalG9eUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO  --> check if we actually do need that**\n",
        "\n",
        "\n",
        "\n",
        "Both the RandomBatchSampler and loader generations are the same as the once `yousefnami` used in his artickle\n",
        "[Reading .h5 Files Faster with PyTorch Datasets](https://towardsdatascience.com/reading-h5-files-faster-with-pytorch-datasets-3ff86938cc)"
      ],
      "metadata": {
        "id": "vsW5vElfPhwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomBatchSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset_length = len(dataset)\n",
        "        self.n_batches = self.dataset_length / self.batch_size\n",
        "        self.batch_ids = ty.randperm(int(self.n_batches))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        for id in self.batch_ids:\n",
        "            idx = ty.arange(id * self.batch_size, (id + 1) * self.batch_size)\n",
        "            for index in idx:\n",
        "                yield int(index)\n",
        "        if int(self.n_batches) < self.n_batches:\n",
        "            idx = ty.arange(int(self.n_batches) * self.batch_size,\n",
        "                            self.dataset_length)\n",
        "            for index in idx:\n",
        "                yield int(index)\n",
        "\n",
        "def normal_loader(dataset, batch_size=32, drop_last=False, shuffle=True):\n",
        "    return DataLoader(dataset,\n",
        "                      batch_size=batch_size,\n",
        "                      drop_last=drop_last,\n",
        "                      shuffle=shuffle)\n",
        "def fast_loader(dataset, batch_size=32, drop_last=False, transforms=None):\n",
        "    return DataLoader(dataset, \n",
        "                      batch_size=None,\n",
        "                      sampler=BatchSampler(RandomBatchSampler(dataset,\n",
        "                                                              batch_size),\n",
        "                                           batch_size=batch_size,\n",
        "                                           drop_last=drop_last))"
      ],
      "metadata": {
        "id": "gUkX3injPIXy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = StockDataset(\"train_data.hdf5\")"
      ],
      "metadata": {
        "id": "5OnFxZblXuW8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = normal_loader(train_data)\n",
        "train_loader_f = fast_loader(train_data)"
      ],
      "metadata": {
        "id": "y84Y1AnrY500"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_load = time.time()\n",
        "for i, (X,y) in enumerate(train_loader_f):\n",
        "    end_load = time.time()\n",
        "    print(i, X.shape, y.shape)\n",
        "    break\n",
        "print( f'Time taken: load({end_load - start_load:.3g}), ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFwtHNEMacE_",
        "outputId": "c586d1ae-a81a-4376-9aac-00dca940c5aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
            "Time taken: load(0.896), \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start_load = time.time()\n",
        "for i, (X,y) in enumerate(train_loader):\n",
        "    end_load = time.time()\n",
        "    print(i, X.shape, y.shape)\n",
        "    break\n",
        "print( f'Time taken: load({end_load - start_load:.3g}), ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLeStHBpX0h6",
        "outputId": "a20cca3d-da44-427a-b75d-1fe59b269d91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
            "Time taken: load(1.53), \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_data = StockDataset(\"train_data.hdf5\")\n",
        "val_data = StockDataset(\"val_data.hdf5\")\n",
        "test_data = StockDataset(\"test_data.hdf5\")\n",
        "\n",
        "train_loader = normal_loader(train_data, batch_size=batch_size)\n",
        "# train_loader_f = fast_loader(train_data, batch_size=batch_size)\n",
        "val_loader = normal_loader(val_data, batch_size=batch_size)\n",
        "# val_loader_f = fast_loader(val_data, batch_size=batch_size)\n",
        "test_loader = normal_loader(test_data, batch_size=batch_size)\n",
        "# test_loader_f = fast_loader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "a7snqZLiOGIj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model "
      ],
      "metadata": {
        "id": "Vpq8FNnJN-o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time2vec**\n",
        "\n",
        "In order to consider both periodic and non-periodic patterns & time rescaling invariance (representation not affected by different time units), we use time2vec.\n",
        "\n",
        "Idea:\n",
        "* Initially use a linear function for first iteration\n",
        "* Call upon a function of the linear function (sin) for every other iteration"
      ],
      "metadata": {
        "id": "87-z-Oh8douU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = None\n",
        "use_cuda = True # set this variable if you want to use cuda\n",
        "if ty.cuda.is_available() and use_cuda:\n",
        "    device = ty.device('cuda:0')"
      ],
      "metadata": {
        "id": "YF5Ae2vxhzuv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time2vec(tau, w0, b0, w1, b1):\n",
        "  #Sticking with sin function since it outperforms other functions\n",
        "  #Tau is the average of z in [x, y, z] = [32, 128, 5]? (Need to double check)\n",
        "  v0 = ty.sin(ty.matmul(tau, w0) + b0)\n",
        "  v1 = ty.matmul(tau, w1) + b1\n",
        "\n",
        "  return ty.cat([v0, v1], 1)"
      ],
      "metadata": {
        "id": "RdqEWXgYOFfa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Time2VecTest(nn.Module):\n",
        "    def __init__(self, seq_len, device):\n",
        "        super(Time2VecTest, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.device = device\n",
        "        self.time_lin_weight = nn.Linear(seq_len, seq_len, device=device)\n",
        "        self.time_periodic_weight = nn.Linear(seq_len, seq_len, device=device)\n",
        "        # nn.init.uniform_(self.time_lin_weight.weight)\n",
        "        # nn.init.uniform_(self.time_periodic_weight.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "        x = ty.mean(x, dim=-1)\n",
        "        x_time_lin = self.time_lin_weight(x).unsqueeze(-1)\n",
        "        x_time_periodic =  ty.sin(self.time_periodic_weight(x)).unsqueeze(-1)\n",
        "        return ty.concat([x_time_lin, x_time_periodic], -1)\n"
      ],
      "metadata": {
        "id": "6MZaSzqhgjDg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our manually created model\n",
        "\n",
        "\n",
        "Note our model is a mix of the classic definition of the transformer discussed in class as well as some modifications to it were taken from the paper Attention Is All You Need and [Jan Schmitz implementation](https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6#:~:text=A%20Transformer%20is%20a%20neural,and%20Multi%2DHead%20Attention%20layer), though unlike his implementaiton we are using pytorch, and we will write our own training funcitonality."
      ],
      "metadata": {
        "id": "W4FjAWHdG3cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_cases = 128\n",
        "dim_vals = 128\n",
        "filter_dim = 128\n",
        "class OneHead(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, device):\n",
        "        super(OneHead, self).__init__()\n",
        "        self.dim_keys = dim_keys\n",
        "        self.dim_val = dim_val\n",
        "        self.device = device\n",
        "        self.query = nn.Linear(7, dim_keys, device=device)  # 7 = 5(open, close, high, low, volume) + 2(time vec)\n",
        "        self.keys = nn.Linear(7, dim_keys, device=device)\n",
        "        self.values = nn.Linear(7, dim_val, device=device)\n",
        "        self.softmax = nn.Softmax(-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  Expects x to be of shape [batch_size, seq_len, 7]\n",
        "        x = x.to(self.device)\n",
        "        q = self.query(x)\n",
        "        k = self.keys(x)\n",
        "        attention = q @ ty.transpose(k, 1, 2)\n",
        "        attention = attention / np.sqrt(self.dim_keys)\n",
        "        attention =  self.softmax(attention)\n",
        "        v = self.values(x)\n",
        "        return attention @ v"
      ],
      "metadata": {
        "id": "JSl-TFedfjez"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MultiHead(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, n_heads, device):\n",
        "        super(MultiHead, self).__init__()\n",
        "        self.dim_keys = dim_keys\n",
        "        self.dim_val = dim_val\n",
        "        self.device = device\n",
        "        self.n_heads = n_heads\n",
        "        self.lin_dim = n_heads * dim_val\n",
        "        self.multi_head = [OneHead(dim_keys, dim_val, device) for _ in range(n_heads)]\n",
        "        self.lin_final_attention = nn.Linear(self.lin_dim, 7,  device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "        attn = [func(x) for func in self.multi_head]\n",
        "        concat_attn = ty.concat(attn, -1)\n",
        "        mult_attn = self.lin_final_attention(concat_attn)\n",
        "        return mult_attn"
      ],
      "metadata": {
        "id": "pwKik0xn3KAU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, n_heads,\n",
        "                 filter_dim, device, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dim_keys = dim_keys\n",
        "        self.dim_val = dim_val\n",
        "        self.device = device\n",
        "        self.n_heads = n_heads\n",
        "        self.multi_hed = MultiHead(dim_keys, dim_val, n_heads, device)\n",
        "        self.drop_out = nn.Dropout(dropout)\n",
        "        self.normilize  = nn.InstanceNorm1d(seq_len, eps=1e-6)\n",
        "        self.f1 = nn.Conv1d(7, filter_dim, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.f2 = nn.Conv1d(filter_dim, 7, 1)\n",
        "        self.f_drop_out = nn.Dropout(dropout)\n",
        "        self.f_norm = nn.InstanceNorm1d(seq_len, eps=1e-6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "        attentions = self.multi_hed(x)\n",
        "        attentions = self.drop_out(attentions)\n",
        "        attentions = self.normilize(attentions + x)\n",
        "        attentions = attentions.permute(0, 2, 1)\n",
        "        filtered = self.relu(self.f1(attentions))\n",
        "        filtered = self.f2(filtered)\n",
        "        filtered = filtered.permute(0, 2, 1)\n",
        "        filtered = self.f_drop_out(filtered)\n",
        "        filtered = self.f_norm(filtered + x)\n",
        "        return filtered"
      ],
      "metadata": {
        "id": "kttMRrzhGOVO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, seq_len, hidden,\n",
        "                 n_heads, filter_dim, device, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.time_enc = Time2VecTest(seq_len, device)\n",
        "        self.enc_1 = Encoder( dim_keys, dim_val, n_heads,\n",
        "                             filter_dim, device, dropout)\n",
        "        self.enc_2 = Encoder( dim_keys, dim_val, n_heads,\n",
        "                             filter_dim, device, dropout)\n",
        "        self.enc_3 = Encoder( dim_keys, dim_val, n_heads,\n",
        "                             filter_dim, device, dropout)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        self.drop_out = nn.Dropout(0.1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin1 = nn.Linear(seq_len, hidden)\n",
        "        self.lin2 = nn.Linear(hidden, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "        time_vec = self.time_enc(x)\n",
        "        x = ty.concat([x, time_vec], -1)\n",
        "        x = self.enc_1(x)\n",
        "        x = self.enc_2(x)\n",
        "        x = self.enc_3(x)\n",
        "        x = ty.squeeze(self.avg_pool(x))\n",
        "        x = self.drop_out(x)\n",
        "        x = self.relu(self.lin1(x))\n",
        "        x = self.drop_out(x)\n",
        "        x = self.lin2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "jGkYZkzHr59m"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# time2vec_m = Time2VecTest(seq_len, device)\n",
        "one_h = Decoder(dim_cases, dim_vals,seq_len, 64,  12, filter_dim, device)\n",
        "# transformer_model = nn.Transformer(d_model=5, nhead=5, num_encoder_layers=12, batch_first=True )\n",
        "\n",
        "for i, (X, y) in enumerate(train_loader):\n",
        "    print(i, X.shape, y.shape)\n",
        "    # x_new  = ty.concat([X, time2vec_m(X)], -1)\n",
        "    # print(x_new.shape)\n",
        "    print(one_h(X).shape)\n",
        "    # transformer_model(x_new)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CfF6_CVz3QQ",
        "outputId": "546bf63f-744d-4447-9bc7-6197fa577595"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
            "torch.Size([32, 128, 7])\n",
            "torch.Size([32, 128])\n",
            "torch.Size([32, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "bOZouTg4AhA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_acuracy(model, data):\n"
      ],
      "metadata": {
        "id": "a4crRAdKHxid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_l, val_l, lr=5.0, epoches=20):\n",
        "\n",
        "    criterion  = nn.CrossEntropyLoss()\n",
        "    optim = ty.optim.SGD(model.parameters(), lr=lr)\n",
        "    scheduler = ty.optim.lr_scheduler.StepLR(optim, 1.0, gamma=0.95)\n",
        "    log_interval = 200\n",
        "\n",
        "    for j in range(epoches):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for i, (X, y) in enumerate(train_l):\n",
        "            out = ty.squeeze(model(X))\n",
        "            loss = criterion(out, y)\n",
        "            optim.zero_grad()\n",
        "            ty.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optim.step()\n",
        "            if i % log_interval:\n",
        "                lr = scheduler.get_last_lr()[0]\n",
        "                cur_loss = total_loss / log_interval\n",
        "                print(f\"[Epoch {j+1:3d}] batch: {i} lr:{lr:02.2f}, [Loss : {cur_loss:5.2f}]\")\n",
        "                total_loss = 0\n",
        "\n"
      ],
      "metadata": {
        "id": "EORD_0ItAjiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Version of transformer "
      ],
      "metadata": {
        "id": "jyv28AnM_SgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HFMsEDb8AgOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}