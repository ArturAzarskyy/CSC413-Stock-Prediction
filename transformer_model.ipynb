{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformer_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArturAzarskyy/CSC413-Stock-Prediction/blob/main/transformer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer model for Stock prediction"
      ],
      "metadata": {
        "id": "9pLJEKQAho8u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparations:\n",
        "\n",
        "Note that torch dataset  and sampler were inspired from `yousefnami`'s article about\n",
        "[Reading .h5 Files Faster with PyTorch Datasets](https://towardsdatascience.com/reading-h5-files-faster-with-pytorch-datasets-3ff86938cc)"
      ],
      "metadata": {
        "id": "JjaPnVGE9pSF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the pre-processed data from the "
      ],
      "metadata": {
        "id": "SlAbOtnh1p-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/amd/')"
      ],
      "metadata": {
        "id": "EunBcf6jhomO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31efdf18-9560-4874-9ef2-81df7e223003"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /amd/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_mvg_avg_f = False"
      ],
      "metadata": {
        "id": "Kq3zQAVM2S04"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if load_mvg_avg_f:\n",
        "    !cp /amd/My\\ Drive/CSC413/Data/sp_data_orig_m_avg.zip /content/\n",
        "    !unzip sp_data_orig.zip\n",
        "else:\n",
        "    !cp /amd/My\\ Drive/CSC413/Data/sp_data_orig.zip /content/\n",
        "    !unzip sp_data_orig.zip"
      ],
      "metadata": {
        "id": "YoOJi5YUjUbF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1eefcb0b-b459-48d7-9dd1-4c149837116c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  sp_data_orig.zip\n",
            "  inflating: test_data.hdf5          \n",
            "  inflating: train_data.hdf5         \n",
            "  inflating: val_data.hdf5           \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports:"
      ],
      "metadata": {
        "id": "oVRXRA0EOSAf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yEFAqEAX_5S3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler\n",
        "from torchvision.transforms import Compose\n",
        "import tables\n",
        "import torch as ty\n",
        "import torch.nn as nn\n",
        "import os.path\n",
        "import numpy as np\n",
        "import time\n",
        "seq_len = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a custom dataset for pytorch"
      ],
      "metadata": {
        "id": "sn4tkdqM1ep4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StockDataset(Dataset):\n",
        "    def __init__(self, file_name, shuffle=True):\n",
        "        super(StockDataset, self).__init__()\n",
        "        hdf5_file = tables.open_file(file_name, mode='r')\n",
        "        assert('data' in hdf5_file.root)\n",
        "        assert('labels' in hdf5_file.root)\n",
        "        self.f_name = file_name\n",
        "        self.data = hdf5_file.root.data\n",
        "        self.lables = hdf5_file.root.labels\n",
        "        self.size = self.data.shape[0]\n",
        "        self.shuffle = shuffle\n",
        "        self.trans_data = Compose([self._from_numpy])\n",
        "        self.trans_labels = Compose([self._from_numpy, self._prepare_class_task])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # print('here', index)\n",
        "        X = np.array(self.data[index, :])\n",
        "        y = np.array(self.lables[index])\n",
        "        if self.shuffle and type(index) == list:\n",
        "            permute = ty.randperm(len(index))\n",
        "            X = X[permute, :]\n",
        "            y = y[permute]\n",
        "            y = self.trans_labels(y)\n",
        "        else:\n",
        "            y = self.trans_data(y)\n",
        "        X = self.trans_data(X)\n",
        "        return X, y\n",
        "\n",
        "    def _prepare_class_task(self, tensor):\n",
        "        return ty.reshape(tensor, (-1,))\n",
        "\n",
        "    def _from_numpy(self, tensor):\n",
        "        return ty.from_numpy(tensor).float()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size"
      ],
      "metadata": {
        "id": "lFk9Zq402m1U"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creaiting samplers and two ways of sampling"
      ],
      "metadata": {
        "id": "lew5NalG9eUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO  --> check if we actually do need that**\n",
        "\n",
        "\n",
        "\n",
        "Both the RandomBatchSampler and loader generations are the same as the once `yousefnami` used in his artickle\n",
        "[Reading .h5 Files Faster with PyTorch Datasets](https://towardsdatascience.com/reading-h5-files-faster-with-pytorch-datasets-3ff86938cc)"
      ],
      "metadata": {
        "id": "vsW5vElfPhwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomBatchSampler(Sampler):\n",
        "    def __init__(self, dataset, batch_size):\n",
        "        self.batch_size = batch_size\n",
        "        self.dataset_length = len(dataset)\n",
        "        self.n_batches = self.dataset_length / self.batch_size\n",
        "        self.batch_ids = ty.randperm(int(self.n_batches))\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        for id in self.batch_ids:\n",
        "            idx = ty.arange(id * self.batch_size, (id + 1) * self.batch_size)\n",
        "            for index in idx:\n",
        "                yield int(index)\n",
        "        if int(self.n_batches) < self.n_batches:\n",
        "            idx = ty.arange(int(self.n_batches) * self.batch_size,\n",
        "                            self.dataset_length)\n",
        "            for index in idx:\n",
        "                yield int(index)\n",
        "\n",
        "def normal_loader(dataset, batch_size=32, drop_last=False, shuffle=True):\n",
        "    return DataLoader(dataset,\n",
        "                      batch_size=batch_size,\n",
        "                      drop_last=drop_last,\n",
        "                      shuffle=shuffle)\n",
        "def fast_loader(dataset, batch_size=32, drop_last=False, transforms=None):\n",
        "    return DataLoader(dataset, \n",
        "                      batch_size=None,\n",
        "                      sampler=BatchSampler(RandomBatchSampler(dataset,\n",
        "                                                              batch_size),\n",
        "                                           batch_size=batch_size,\n",
        "                                           drop_last=drop_last))"
      ],
      "metadata": {
        "id": "gUkX3injPIXy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = StockDataset(\"train_data.hdf5\")"
      ],
      "metadata": {
        "id": "5OnFxZblXuW8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = normal_loader(train_data)\n",
        "train_loader_f = fast_loader(train_data)"
      ],
      "metadata": {
        "id": "y84Y1AnrY500"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_load = time.time()\n",
        "for i, (X,y) in enumerate(train_loader_f):\n",
        "    end_load = time.time()\n",
        "    print(i, X.shape, y.shape)\n",
        "    break\n",
        "print( f'Time taken: load({end_load - start_load:.3g}), ')"
      ],
      "metadata": {
        "id": "fFwtHNEMacE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67410edb-c49a-44b8-b79b-ce038cf23d1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
            "Time taken: load(0.74), \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "start_load = time.time()\n",
        "for i, (X,y) in enumerate(train_loader):\n",
        "    end_load = time.time()\n",
        "    print(i, X.shape, y.shape)\n",
        "    break\n",
        "print( f'Time taken: load({end_load - start_load:.3g}), ')"
      ],
      "metadata": {
        "id": "TLeStHBpX0h6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ed3987f-2530-47bc-be37-228466014b78"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
            "Time taken: load(1.24), \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_data = StockDataset(\"train_data.hdf5\")\n",
        "val_data = StockDataset(\"val_data.hdf5\")\n",
        "test_data = StockDataset(\"test_data.hdf5\")\n",
        "\n",
        "train_loader = normal_loader(train_data, batch_size=batch_size)\n",
        "# train_loader_f = fast_loader(train_data, batch_size=batch_size)\n",
        "val_loader = normal_loader(val_data, batch_size=batch_size)\n",
        "# val_loader_f = fast_loader(val_data, batch_size=batch_size)\n",
        "test_loader = normal_loader(test_data, batch_size=batch_size)\n",
        "# test_loader_f = fast_loader(test_data, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "a7snqZLiOGIj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "id": "V7oeUOA1eQmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862f6338-41a4-4a70-d6dc-de1dedb755c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12573778"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model "
      ],
      "metadata": {
        "id": "Vpq8FNnJN-o-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Time2vec**\n",
        "\n",
        "In order to consider both periodic and non-periodic patterns & time rescaling invariance (representation not affected by different time units), we use time2vec.\n",
        "\n",
        "Idea:\n",
        "* Initially use a linear function for first iteration\n",
        "* Call upon a function of the linear function (sin) for every other iteration"
      ],
      "metadata": {
        "id": "87-z-Oh8douU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = None\n",
        "use_cuda = True # set this variable if you want to use cuda\n",
        "if ty.cuda.is_available() and use_cuda:\n",
        "    device = ty.device('cuda:0')"
      ],
      "metadata": {
        "id": "YF5Ae2vxhzuv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time2vec(tau, w0, b0, w1, b1):\n",
        "  #Sticking with sin function since it outperforms other functions\n",
        "  #Tau is the average of z in [x, y, z] = [32, 128, 5]? (Need to double check)\n",
        "  v0 = ty.sin(ty.matmul(tau, w0) + b0)\n",
        "  v1 = ty.matmul(tau, w1) + b1\n",
        "\n",
        "  return ty.cat([v0, v1], 1)"
      ],
      "metadata": {
        "id": "RdqEWXgYOFfa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Time2VecTest(nn.Module):\n",
        "    def __init__(self, seq_len, device):\n",
        "        super(Time2VecTest, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.device = device\n",
        "        self.time_lin_weight = nn.Linear(seq_len, seq_len, device=device)\n",
        "        self.time_periodic_weight = nn.Linear(seq_len, seq_len, device=device)\n",
        "        # nn.init.uniform_(self.time_lin_weight.weight)\n",
        "        # nn.init.uniform_(self.time_periodic_weight.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(self.device)\n",
        "        x = ty.mean(x, dim=-1)\n",
        "        x_time_lin = self.time_lin_weight(x).unsqueeze(-1)\n",
        "        x_time_periodic =  ty.sin(self.time_periodic_weight(x)).unsqueeze(-1)\n",
        "        return ty.concat([x_time_lin, x_time_periodic], -1)\n"
      ],
      "metadata": {
        "id": "6MZaSzqhgjDg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our manually created model\n",
        "\n",
        "\n",
        "Note our model is a mix of the classic definition of the transformer discussed in class as well as some modifications to it were taken from the paper Attention Is All You Need and [Jan Schmitz implementation](https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6#:~:text=A%20Transformer%20is%20a%20neural,and%20Multi%2DHead%20Attention%20layer), though unlike his implementaiton we are using pytorch, and we will write our own training funcitonality."
      ],
      "metadata": {
        "id": "W4FjAWHdG3cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim_cases = 128\n",
        "dim_vals = 128\n",
        "filter_dim = 128\n",
        "class OneHead(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, device):\n",
        "        super(OneHead, self).__init__()\n",
        "        self.dim_keys = dim_keys\n",
        "        self.dim_val = dim_val\n",
        "        self.device = device\n",
        "        self.query = nn.Linear(7, dim_keys, device=device)  # 7 = 5(open, close, high, low, volume) + 2(time vec)\n",
        "        self.keys = nn.Linear(7, dim_keys, device=device)\n",
        "        self.values = nn.Linear(7, dim_val, device=device)\n",
        "        self.softmax = nn.Softmax(-1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  Expects x to be of shape [batch_size, seq_len, 7]\n",
        "        q = self.query(x)\n",
        "        k = self.keys(x)\n",
        "        attention = q @ ty.transpose(k, 1, 2)\n",
        "        attention = attention / np.sqrt(self.dim_keys)\n",
        "        attention =  self.softmax(attention)\n",
        "        v = self.values(x)\n",
        "        return attention @ v"
      ],
      "metadata": {
        "id": "JSl-TFedfjez"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MultiHead(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, n_heads, device):\n",
        "        super(MultiHead, self).__init__()\n",
        "        self.dim_keys = dim_keys\n",
        "        self.dim_val = dim_val\n",
        "        self.device = device\n",
        "        self.n_heads = n_heads\n",
        "        self.lin_dim = n_heads * dim_val\n",
        "        self.multi_head = [OneHead(dim_keys, dim_val, device) for _ in range(n_heads)]\n",
        "        self.lin_final_attention = nn.Linear(self.lin_dim, 7,  device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn = [func(x) for func in self.multi_head]\n",
        "        concat_attn = ty.concat(attn, -1)\n",
        "        mult_attn = self.lin_final_attention(concat_attn)\n",
        "        return mult_attn"
      ],
      "metadata": {
        "id": "pwKik0xn3KAU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, n_heads,\n",
        "                 filter_dim, device, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dim_keys = dim_keys\n",
        "        self.dim_val = dim_val\n",
        "        self.device = device\n",
        "        self.n_heads = n_heads\n",
        "        self.multi_hed = MultiHead(dim_keys, dim_val, n_heads, device)\n",
        "        self.drop_out = nn.Dropout(dropout)\n",
        "        self.normilize  = nn.InstanceNorm1d(seq_len, eps=1e-6)\n",
        "        self.f1 = nn.Conv1d(7, filter_dim, 1,  device=device)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.f2 = nn.Conv1d(filter_dim, 7, 1,  device=device)\n",
        "        self.f_drop_out = nn.Dropout(dropout)\n",
        "        self.f_norm = nn.InstanceNorm1d(seq_len, eps=1e-6)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attentions = self.multi_hed(x)\n",
        "        attentions = self.drop_out(attentions)\n",
        "        attentions = self.normilize(attentions + x)\n",
        "        attentions = attentions.permute(0, 2, 1)\n",
        "        filtered = self.relu(self.f1(attentions))\n",
        "        filtered = self.f2(filtered)\n",
        "        filtered = filtered.permute(0, 2, 1)\n",
        "        filtered = self.f_drop_out(filtered)\n",
        "        filtered = self.f_norm(filtered + x)\n",
        "        return filtered"
      ],
      "metadata": {
        "id": "kttMRrzhGOVO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dim_keys, dim_val, seq_len, hidden,\n",
        "                 n_heads, filter_dim, device, dropout=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.time_enc = Time2VecTest(seq_len, device)\n",
        "        self.enc_1 = Encoder( dim_keys, dim_val, n_heads,\n",
        "                             filter_dim, device, dropout)\n",
        "        self.enc_2 = Encoder( dim_keys, dim_val, n_heads,\n",
        "                             filter_dim, device, dropout)\n",
        "        self.enc_3 = Encoder( dim_keys, dim_val, n_heads,\n",
        "                             filter_dim, device, dropout)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        self.drop_out = nn.Dropout(0.1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.lin1 = nn.Linear(seq_len, hidden,  device=device)\n",
        "        self.lin2 = nn.Linear(hidden, 1,  device=device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        time_vec = self.time_enc(x)\n",
        "        x = ty.concat([x, time_vec], -1)\n",
        "        x = self.enc_1(x)\n",
        "        x = self.enc_2(x)\n",
        "        x = self.enc_3(x)\n",
        "        x = ty.squeeze(self.avg_pool(x))\n",
        "        x = self.drop_out(x)\n",
        "        x = self.relu(self.lin1(x))\n",
        "        x = self.drop_out(x)\n",
        "        x = self.lin2(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "jGkYZkzHr59m"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training"
      ],
      "metadata": {
        "id": "bOZouTg4AhA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eval_loss_loss(model, data_loader, data_len, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss  = 0\n",
        "    for i, (X, y) in enumerate(data_loader):\n",
        "        out =  ty.squeeze(model(X))\n",
        "        total_loss += batch_size * criterion(out, y.to(device)).item()\n",
        "    return total_loss / data_len\n"
      ],
      "metadata": {
        "id": "V1hc84ZcP8zZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_l, val_l, train_d_len, val_d_len, device, lr=1e-10, epoches=20):\n",
        "\n",
        "    criterion  = nn.MSELoss()\n",
        "    # optim = ty.optim.SGD(model.parameters(), lr=lr, weight_decay=0.99, momentum=0.6)\n",
        "    optim = ty.optim.Adam(model.parameters())\n",
        "    # scheduler = ty.optim.lr_scheduler.StepLR(optim, 1.0, gamma=0.95)\n",
        "    log_interval = 200\n",
        "\n",
        "    for j in range(epoches):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        print(f\"==== Eproch {j+1} started ====\")\n",
        "        for i, (X, y) in enumerate(train_l):\n",
        "            out = model(X.to(device)).reshape((-1,))\n",
        "            loss = criterion(out, y.to(device))\n",
        "            optim.zero_grad()\n",
        "            # ty.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "            optim.step()\n",
        "            total_loss += loss.item()\n",
        "            if i % log_interval == 0 and i > 0:\n",
        "                # lr = scheduler.get_last_lr()[0]\n",
        "                cur_loss = total_loss / log_interval\n",
        "                # print(f\"batch: {i} lr:{lr:02.2f}, [Loss : {cur_loss:5.2f}]\")\n",
        "                print(f\"batch: {i}, [Loss : {cur_loss:5.2f}]\")\n",
        "                total_loss = 0\n",
        "\n",
        "        print(f\"validation evel loss {get_eval_loss_loss(model, val_l, val_d_len, criterion, device):5.2f}\")\n",
        "\n",
        "        \n",
        "\n"
      ],
      "metadata": {
        "id": "EORD_0ItAjiu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Decoder(dim_cases, dim_vals, seq_len, 64, 10, filter_dim, device)\n",
        "train(model, train_loader, val_loader, len(train_data), len(val_data), device)"
      ],
      "metadata": {
        "id": "Ek9cBq7Wgyr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "e93ce554-49cb-4193-b1b3-8b3c1f4dd4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Eproch 1 started ====\n",
            "batch: 200, [Loss :   nan]\n",
            "batch: 400, [Loss :   nan]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f1b2d360b61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-f4e2fab9f787>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_l, val_l, train_d_len, val_d_len, device, lr, epoches)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"==== Eproch {j+1} started ====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-7e2abf46dcd6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print('here', index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tables/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# First, try with a regular selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;31m# Then, try with a point-wise selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tables/array.py\u001b[0m in \u001b[0;36m_read_slice\u001b[0;34m(self, startl, stopl, stepl, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;31m# Arrays that have non-zero dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_read_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;31m# For zero-shaped arrays, return the scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Closing remaining open files:val_data.hdf5...donetest_data.hdf5...donetrain_data.hdf5...donetrain_data.hdf5...done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PyTorch Version of transformer "
      ],
      "metadata": {
        "id": "jyv28AnM_SgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HFMsEDb8AgOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}