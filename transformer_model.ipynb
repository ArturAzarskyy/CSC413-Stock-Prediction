{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ArturAzarskyy/CSC413-Stock-Prediction/blob/main/transformer_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9pLJEKQAho8u"
   },
   "source": [
    "# Transformer model for Stock prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjaPnVGE9pSF"
   },
   "source": [
    "## Preparations:\n",
    "\n",
    "Note that the Torch Dataset and Sampler were inspired from `yousefnami`'s article about\n",
    "[Reading .h5 Files Faster with PyTorch Datasets](https://towardsdatascience.com/reading-h5-files-faster-with-pytorch-datasets-3ff86938cc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlAbOtnh1p-y"
   },
   "source": [
    "### Getting the pre-processed data from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EunBcf6jhomO",
    "outputId": "2daf8c2e-ed88-4b32-951b-b6efde1d4116"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /amd/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/amd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Kq3zQAVM2S04"
   },
   "outputs": [],
   "source": [
    "load_mvg_avg_f = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoOJi5YUjUbF",
    "outputId": "d961ad97-150c-45db-f495-59bedecc8ca8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  sp_data_orig.zip\n",
      "  inflating: test_data.hdf5          \n",
      "  inflating: train_data.hdf5         \n",
      "  inflating: val_data.hdf5           \n"
     ]
    }
   ],
   "source": [
    "if load_mvg_avg_f:\n",
    "    !cp /amd/My\\ Drive/CSC413/Data/sp_data_orig_m_avg.zip /content/\n",
    "    !unzip sp_data_orig.zip\n",
    "else:\n",
    "    !cp /amd/My\\ Drive/CSC413/Data/sp_data_orig.zip /content/\n",
    "    !unzip sp_data_orig.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVRXRA0EOSAf"
   },
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yEFAqEAX_5S3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, Sampler, BatchSampler\n",
    "from torchvision.transforms import Compose\n",
    "import tables\n",
    "import torch as ty\n",
    "import torch.nn as nn\n",
    "import os.path\n",
    "import numpy as np\n",
    "import time\n",
    "# import pdb # Python Debugger\n",
    "seq_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn4tkdqM1ep4"
   },
   "source": [
    "### Creating a custom dataset for pytorch\n",
    "\n",
    "The data frames saved to files in the preprocessing stage (`transformer_prepros.ipynb`) are read into a DataSet class that stores a file's data and can return the entry at an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lFk9Zq402m1U"
   },
   "outputs": [],
   "source": [
    "class StockDataset(Dataset):\n",
    "    def __init__(self, file_name, shuffle=True):\n",
    "        super(StockDataset, self).__init__()\n",
    "        hdf5_file = tables.open_file(file_name, mode='r')\n",
    "        assert('data' in hdf5_file.root) # check correct file form\n",
    "        assert('labels' in hdf5_file.root)\n",
    "        self.f_name = file_name\n",
    "        self.data = hdf5_file.root.data\n",
    "        self.lables = hdf5_file.root.labels\n",
    "        self.size = self.data.shape[0]\n",
    "        self.shuffle = shuffle\n",
    "        self.trans_data = Compose([self._from_numpy])\n",
    "        self.trans_labels = Compose([self._from_numpy, self._prepare_class_task])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X = np.array(self.data[index, :])\n",
    "        y = np.array(self.lables[index])\n",
    "        if self.shuffle and type(index) == list:\n",
    "            permute = ty.randperm(len(index))\n",
    "            X = X[permute, :]\n",
    "            y = y[permute]\n",
    "            y = self.trans_labels(y)\n",
    "        else:\n",
    "            y = self.trans_data(y)\n",
    "        X = self.trans_data(X)\n",
    "        return X, y\n",
    "\n",
    "    def _prepare_class_task(self, tensor):\n",
    "        return ty.reshape(tensor, (-1,))\n",
    "\n",
    "    def _from_numpy(self, tensor):\n",
    "        return ty.from_numpy(tensor).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lew5NalG9eUq"
   },
   "source": [
    "### Creating samplers and two ways of sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsW5vElfPhwI"
   },
   "source": [
    "Both the RandomBatchSampler and loader generations are the same as the ones `yousefnami` used in his article\n",
    "[Reading .h5 Files Faster with PyTorch Datasets](https://towardsdatascience.com/reading-h5-files-faster-with-pytorch-datasets-3ff86938cc).\n",
    "\n",
    "We would continue to do further analysis to see if this step is necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gUkX3injPIXy"
   },
   "outputs": [],
   "source": [
    "class RandomBatchSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_length = len(dataset)\n",
    "        self.n_batches = self.dataset_length / self.batch_size\n",
    "        self.batch_ids = ty.randperm(int(self.n_batches))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for id in self.batch_ids:\n",
    "            idx = ty.arange(id * self.batch_size, (id + 1) * self.batch_size)\n",
    "            for index in idx:\n",
    "                yield int(index)\n",
    "        if int(self.n_batches) < self.n_batches:\n",
    "            idx = ty.arange(int(self.n_batches) * self.batch_size,\n",
    "                            self.dataset_length)\n",
    "            for index in idx:\n",
    "                yield int(index)\n",
    "\n",
    "def normal_loader(dataset, batch_size=32, drop_last=False, shuffle=True):\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      drop_last=drop_last,\n",
    "                      shuffle=shuffle)\n",
    "def fast_loader(dataset, batch_size=32, drop_last=False, transforms=None):\n",
    "    return DataLoader(dataset, \n",
    "                      batch_size=None,\n",
    "                      sampler=BatchSampler(RandomBatchSampler(dataset,\n",
    "                                                              batch_size),\n",
    "                                           batch_size=batch_size,\n",
    "                                           drop_last=drop_last))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5OnFxZblXuW8"
   },
   "outputs": [],
   "source": [
    "train_data = StockDataset(\"train_data.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "y84Y1AnrY500"
   },
   "outputs": [],
   "source": [
    "train_loader = normal_loader(train_data)\n",
    "train_loader_f = fast_loader(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fFwtHNEMacE_",
    "outputId": "5c36c43a-13ac-4b81-b19f-366a6eb17313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
      "Time taken: load(0.848), \n"
     ]
    }
   ],
   "source": [
    "start_load = time.time()\n",
    "for i, (X,y) in enumerate(train_loader_f):\n",
    "    end_load = time.time()\n",
    "    print(i, X.shape, y.shape)\n",
    "    break\n",
    "print( f'Time taken: load({end_load - start_load:.3g}), ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TLeStHBpX0h6",
    "outputId": "d67cd9d4-e185-4c1c-e213-77073edc97b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([32, 128, 5]) torch.Size([32])\n",
      "Time taken: load(1.5), \n"
     ]
    }
   ],
   "source": [
    "start_load = time.time()\n",
    "for i, (X,y) in enumerate(train_loader):\n",
    "    end_load = time.time()\n",
    "    print(i, X.shape, y.shape)\n",
    "    break\n",
    "print( f'Time taken: load({end_load - start_load:.3g}), ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a7snqZLiOGIj"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "train_data = StockDataset(\"train_data.hdf5\")\n",
    "val_data = StockDataset(\"val_data.hdf5\")\n",
    "test_data = StockDataset(\"test_data.hdf5\")\n",
    "\n",
    "train_loader = normal_loader(train_data, batch_size=batch_size)\n",
    "# train_loader_f = fast_loader(train_data, batch_size=batch_size)\n",
    "val_loader = normal_loader(val_data, batch_size=batch_size)\n",
    "# val_loader_f = fast_loader(val_data, batch_size=batch_size)\n",
    "test_loader = normal_loader(test_data, batch_size=batch_size)\n",
    "# test_loader_f = fast_loader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7oeUOA1eQmO",
    "outputId": "ffd9e2b0-73f5-4df9-82ae-4b6b9e944197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12573778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vpq8FNnJN-o-"
   },
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87-z-Oh8douU"
   },
   "source": [
    "**Time2vec**\n",
    "\n",
    "In order to consider both periodic and non-periodic patterns & time rescaling invariance (representation not affected by different time units), we use time2vec.\n",
    "\n",
    "Idea:\n",
    "* Initially use a linear function for first iteration\n",
    "* Call upon a function (we will use the sine function) of the linear function for every other iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YF5Ae2vxhzuv"
   },
   "outputs": [],
   "source": [
    "device = None\n",
    "use_cuda = True\n",
    "if ty.cuda.is_available() and use_cuda:\n",
    "    device = ty.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RdqEWXgYOFfa"
   },
   "outputs": [],
   "source": [
    "def time2vec(tau, w0, b0, w1, b1):\n",
    "  # sin function outperforms other functions\n",
    "  # Tau is the average of z in [x, y, z] = [32, 128, 5]? (Need to double check)\n",
    "  v0 = ty.sin(ty.matmul(tau, w0) + b0)\n",
    "  v1 = ty.matmul(tau, w1) + b1\n",
    "\n",
    "  return ty.cat([v0, v1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6MZaSzqhgjDg"
   },
   "outputs": [],
   "source": [
    "class Time2VecTest(nn.Module):\n",
    "    def __init__(self, seq_len, device):\n",
    "        super(Time2VecTest, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.device = device\n",
    "        self.time_lin_weight = nn.Linear(seq_len, seq_len, device=device)\n",
    "        self.time_periodic_weight = nn.Linear(seq_len, seq_len, device=device)\n",
    "        # nn.init.uniform_(self.time_lin_weight.weight)\n",
    "        # nn.init.uniform_(self.time_periodic_weight.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(self.device)\n",
    "        x = ty.mean(x, dim=-1)\n",
    "        x_time_lin = self.time_lin_weight(x).unsqueeze(-1)\n",
    "        x_time_periodic =  ty.sin(self.time_periodic_weight(x)).unsqueeze(-1)\n",
    "        return ty.concat([x_time_lin, x_time_periodic], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4FjAWHdG3cn"
   },
   "source": [
    "### Manually created model\n",
    "\n",
    "\n",
    "Our model is a combination of the classic definition of the transformer discussed in lecture and the modifications to it seen in the paper \"Attention Is All You Need\", as well as the [Jan Schmitz implementation](https://towardsdatascience.com/stock-predictions-with-state-of-the-art-transformer-and-time-embeddings-3a4485237de6#:~:text=A%20Transformer%20is%20a%20neural,and%20Multi%2DHead%20Attention%20layer). Unlike the latter implementation we are using PyTorch, and we use own training functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "JSl-TFedfjez"
   },
   "outputs": [],
   "source": [
    "dim_cases = 128\n",
    "dim_vals = 128\n",
    "filter_dim = 128\n",
    "class OneHead(nn.Module):\n",
    "    def __init__(self, dim_keys, dim_val, device):\n",
    "        super(OneHead, self).__init__()\n",
    "        self.dim_keys = dim_keys\n",
    "        self.dim_val = dim_val\n",
    "        self.device = device\n",
    "        self.query = nn.Linear(7, dim_keys, device=device)  # 7 = 5(open, close, high, low, volume) + 2(time vec)\n",
    "        self.keys = nn.Linear(7, dim_keys, device=device)\n",
    "        self.values = nn.Linear(7, dim_val, device=device)\n",
    "        self.softmax = nn.Softmax(-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #  Expects x to be of shape [batch_size, seq_len, 7]\n",
    "        q = self.query(x)\n",
    "        k = self.keys(x)\n",
    "        attention = q @ ty.transpose(k, 1, 2)\n",
    "        attention = attention / np.sqrt(self.dim_keys)\n",
    "        attention =  self.softmax(attention)\n",
    "        v = self.values(x)\n",
    "        return attention @ v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pwKik0xn3KAU"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, dim_keys, dim_val, n_heads, device):\n",
    "        super(MultiHead, self).__init__()\n",
    "        self.dim_keys = dim_keys\n",
    "        self.dim_val = dim_val\n",
    "        self.device = device\n",
    "        self.n_heads = n_heads\n",
    "        self.lin_dim = n_heads * dim_val\n",
    "        self.multi_head = [OneHead(dim_keys, dim_val, device) for _ in range(n_heads)]\n",
    "        self.lin_final_attention = nn.Linear(self.lin_dim, 7,  device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn = [func(x) for func in self.multi_head]\n",
    "        concat_attn = ty.concat(attn, -1)\n",
    "        mult_attn = self.lin_final_attention(concat_attn)\n",
    "        return mult_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kttMRrzhGOVO"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_keys, dim_val, n_heads,\n",
    "                 filter_dim, device, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dim_keys = dim_keys\n",
    "        self.dim_val = dim_val\n",
    "        self.device = device\n",
    "        self.n_heads = n_heads\n",
    "        self.multi_hed = MultiHead(dim_keys, dim_val, n_heads, device)\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "        self.normilize  = nn.InstanceNorm1d(seq_len, eps=1e-6)\n",
    "        self.f1 = nn.Conv1d(7, filter_dim, 1,  device=device)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.f2 = nn.Conv1d(filter_dim, 7, 1,  device=device)\n",
    "        self.f_drop_out = nn.Dropout(dropout)\n",
    "        self.f_norm = nn.InstanceNorm1d(seq_len, eps=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attentions = self.multi_hed(x)\n",
    "        attentions = self.drop_out(attentions)\n",
    "        attentions = self.normilize(attentions + x)\n",
    "        attentions = attentions.permute(0, 2, 1)\n",
    "        filtered = self.relu(self.f1(attentions))\n",
    "        filtered = self.f2(filtered)\n",
    "        filtered = filtered.permute(0, 2, 1)\n",
    "        filtered = self.f_drop_out(filtered)\n",
    "        filtered = self.f_norm(filtered + x)\n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "jGkYZkzHr59m"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dim_keys, dim_val, seq_len, hidden,\n",
    "                 n_heads, filter_dim, device, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.time_enc = Time2VecTest(seq_len, device)\n",
    "        self.enc_1 = Encoder( dim_keys, dim_val, n_heads,\n",
    "                             filter_dim, device, dropout)\n",
    "        self.enc_2 = Encoder( dim_keys, dim_val, n_heads,\n",
    "                             filter_dim, device, dropout)\n",
    "        self.enc_3 = Encoder( dim_keys, dim_val, n_heads,\n",
    "                             filter_dim, device, dropout)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.drop_out = nn.Dropout(0.1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin1 = nn.Linear(seq_len, hidden,  device=device)\n",
    "        self.lin2 = nn.Linear(hidden, 1,  device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        time_vec = self.time_enc(x)\n",
    "        x = ty.concat([x, time_vec], -1)\n",
    "        x = self.enc_1(x)\n",
    "        x = self.enc_2(x)\n",
    "        x = self.enc_3(x)\n",
    "        x = ty.squeeze(self.avg_pool(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = self.relu(self.lin1(x))\n",
    "        x = self.drop_out(x)\n",
    "        x = self.lin2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOZouTg4AhA1"
   },
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "V1hc84ZcP8zZ"
   },
   "outputs": [],
   "source": [
    "def get_eval_loss_loss(model, data_loader, data_len, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss  = 0\n",
    "    for i, (X, y) in enumerate(data_loader):\n",
    "        out =  ty.squeeze(model(X))\n",
    "        total_loss += batch_size * criterion(out, y.to(device)).item()\n",
    "    return total_loss / data_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "EORD_0ItAjiu"
   },
   "outputs": [],
   "source": [
    "def train(model, train_l, val_l, train_d_len, val_d_len, device, lr=1e-10, epoches=20):\n",
    "\n",
    "    criterion  = nn.MSELoss()\n",
    "    # optim = ty.optim.SGD(model.parameters(), lr=lr, weight_decay=0.99, momentum=0.6)\n",
    "    optim = ty.optim.Adam(model.parameters())\n",
    "    # scheduler = ty.optim.lr_scheduler.StepLR(optim, 1.0, gamma=0.95)\n",
    "    log_interval = 200\n",
    "\n",
    "    for j in range(epoches):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        print(f\"==== Eproch {j+1} started ====\")\n",
    "        for i, (X, y) in enumerate(train_l):\n",
    "            out = model(X.to(device)).reshape((-1,))\n",
    "            loss = criterion(out, y.to(device))\n",
    "            optim.zero_grad()\n",
    "            # ty.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            optim.step()\n",
    "            print(loss)\n",
    "            print(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            if i > 0:\n",
    "                # lr = scheduler.get_last_lr()[0]\n",
    "                cur_loss = total_loss / log_interval\n",
    "                # print(f\"batch: {i} lr:{lr:02.2f}, [Loss : {cur_loss:5.2f}]\")\n",
    "                print(f\"batch: {i}, [Loss : {cur_loss:5.2f}]\")\n",
    "                total_loss = 0\n",
    "\n",
    "        print(f\"validation evel loss {get_eval_loss_loss(model, val_l, val_d_len, criterion, device):5.2f}\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "Ek9cBq7Wgyr7",
    "outputId": "a8953847-aac7-42bf-8ef9-f7b72bbe2a56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== Eproch 1 started ====\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "0.1346912682056427\n",
      "tensor(0.1296, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "0.12955591082572937\n",
      "batch: 1, [Loss :  0.00]\n",
      "tensor(0.1368, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "0.136806920170784\n",
      "batch: 2, [Loss :  0.00]\n",
      "tensor(0.1157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "0.11566568166017532\n",
      "batch: 3, [Loss :  0.00]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f1b2d360b61a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_cases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-b671f8e4cde4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_l, val_l, train_d_len, val_d_len, device, lr, epoches)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"==== Eproch {j+1} started ====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_l\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-7e2abf46dcd6>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print('here', index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tables/array.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# First, try with a regular selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_indexing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0;31m# Then, try with a point-wise selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tables/array.py\u001b[0m in \u001b[0;36m_read_slice\u001b[0;34m(self, startl, stopl, stepl, shape)\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;31m# Arrays that have non-zero dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_g_read_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstartl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0;31m# For zero-shaped arrays, return the scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnparr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Decoder(dim_cases, dim_vals, seq_len, 64, 10, filter_dim, device)\n",
    "train(model, train_loader, val_loader, len(train_data), len(val_data), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyv28AnM_SgZ"
   },
   "source": [
    "### PyTorch Version of transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFMsEDb8AgOb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transformer_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
