{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ArturAzarskyy/CSC413-Stock-Prediction/blob/main/transformer_prepros.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jhuhIQFovDqx"
   },
   "source": [
    "# Model Preprocessing\n",
    "\n",
    "Note that some parts of ideas and code was taken form the Jan Schmitz notebook on IBM stock prediciton [IBM stock predictor](https://github.com/JanSchm/CapMarket/blob/master/bot_experiments/IBM_Transformer%2BTimeEmbedding.ipynb). Though Jan S. worked only with one stock we extended the idea to multiple stocks as well as used different dataset. We are also looking at a bit different model as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "QlDcGQ5Gx6B_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: /content/kaggle.json\n",
      "cp: directory /Users/lorybuttazzoni/.kaggle does not exist\n",
      "zsh:1: command not found: kaggle\n",
      "unzip:  cannot find or open amex-nyse-nasdaq-stock-histories.zip, amex-nyse-nasdaq-stock-histories.zip.zip or amex-nyse-nasdaq-stock-histories.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!echo '{\"username\":\"arturusmaximus\",\"key\":\"4f14194978499e9ae1ad6adb74b94add\"}' > /content/kaggle.json\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "# !kaggle datasets download -d borismarjanovic/price-volume-data-for-all-us-stocks-etfs\n",
    "!kaggle datasets download -d qks1lver/amex-nyse-nasdaq-stock-histories\n",
    "# !unzip price-volume-data-for-all-us-stocks-etfs.zip\n",
    "!unzip amex-nyse-nasdaq-stock-histories.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DBzAmkzAMVgZ"
   },
   "outputs": [],
   "source": [
    "import tables\n",
    "import pandas as pd\n",
    "import torch as ty\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OAo4he2sHyRu",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sets: training, validation, test\n",
    "train_file = tables.open_file(\"train_data.hdf5\", mode='w')\n",
    "val_file = tables.open_file(\"val_data.hdf5\", mode='w')\n",
    "test_file = tables.open_file(\"test_data.hdf5\", mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the data and labels for the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uDf-WA6-xi7I"
   },
   "outputs": [],
   "source": [
    "time_step = 1\n",
    "stock_history_length = 128 # this does not include the label\n",
    "num_params = 5\n",
    "do_moving_avg = True # case for considering the moving average\n",
    "moving_dist = 5\n",
    "# stock_history_length = 63 # this does not include the label\n",
    "\n",
    "filters = tables.Filters(complevel=5, complib='blosc')\n",
    "\n",
    "train_data  = train_file.create_earray(train_file.root, 'data',\n",
    "                                      tables.Atom.from_dtype(np.dtype('float64')),\n",
    "                                      shape=(0, stock_history_length, num_params),\n",
    "                                      filters=filters,\n",
    "                                      expectedrows=10e6)\n",
    "train_labels = train_file.create_earray(train_file.root, 'labels',\n",
    "                                       tables.Atom.from_dtype(np.dtype('float64')),\n",
    "                                       shape=(0,),\n",
    "                                       filters=filters,\n",
    "                                       expectedrows=10e6)\n",
    "val_data = val_file.create_earray(val_file.root, 'data',\n",
    "                                  tables.Atom.from_dtype(np.dtype('float64')),\n",
    "                                  shape=(0, stock_history_length, num_params),\n",
    "                                  filters=filters,\n",
    "                                  expectedrows=4e6)\n",
    "val_labels = val_file.create_earray(val_file.root, 'labels',\n",
    "                                   tables.Atom.from_dtype(np.dtype('float64')),\n",
    "                                   shape=(0,),\n",
    "                                   filters=filters,\n",
    "                                   expectedrows=4e6)\n",
    "test_data = test_file.create_earray(test_file.root, 'data',\n",
    "                                   tables.Atom.from_dtype(np.dtype('float64')),\n",
    "                                   shape=(0, stock_history_length, num_params),\n",
    "                                   filters=filters,\n",
    "                                   expectedrows=1e6)\n",
    "test_labels = test_file.create_earray(test_file.root, 'labels',\n",
    "                                     tables.Atom.from_dtype(np.dtype('float64')),\n",
    "                                     shape=(0,),\n",
    "                                     filters=filters,\n",
    "                                     expectedrows=1e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create data frames for train/valid/test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2uouYOPwyLKZ"
   },
   "outputs": [],
   "source": [
    "with open('all_symbols.txt') as topo_file:\n",
    "    for line in topo_file:\n",
    "        \n",
    "        if os.path.isfile(\"full_history/\"+line[:-1]+\".csv\"):\n",
    "            df = pd.read_csv(\"full_history/\"+line[:-1]+\".csv\",\n",
    "                             delimiter=',', \n",
    "                             usecols=['date', 'open', 'high', 'low', 'close', 'volume'])\n",
    "            \n",
    "            if len(df.index.values) == 0:\n",
    "                continue\n",
    "            df['volume'].replace(to_replace=0, method='ffill', inplace=True) \n",
    "            df.sort_values('date', inplace=True)\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            if do_moving_avg:\n",
    "                df[['open', 'high', 'low', 'close', \n",
    "                    'volume']] = df[['open', 'high',\n",
    "                                     'low', 'close',\n",
    "                                     'volume']].rolling(moving_dist).mean() \n",
    "\n",
    "            # - Convert to Percentage Change -\n",
    "            df.dropna(how='any', axis=0, inplace=True)\n",
    "            df['open'] = df['open'].pct_change()\n",
    "            df['high'] = df['high'].pct_change()\n",
    "            df['low'] = df['low'].pct_change()\n",
    "            df['close'] = df['close'].pct_change()\n",
    "            df['volume'] = df['volume'].pct_change()\n",
    "            df.dropna(how='any', axis=0, inplace=True)\n",
    "\n",
    "            # - Sort -\n",
    "            if int(0.2*df.shape[0]) < stock_history_length+1 or int(0.1*df.shape[0]) < stock_history_length+1:\n",
    "                continue\n",
    "            valid_start = sorted(df.index.values)[-int(0.3*df.shape[0])]  \n",
    "            test_start = sorted(df.index.values)[-int(0.1*df.shape[0])]\n",
    "            min_return = min(df[(df.index < valid_start)][['open', 'high', 'low', 'close']].min(axis=0))\n",
    "            max_return = max(df[(df.index < valid_start)][['open', 'high', 'low', 'close']].max(axis=0))\n",
    "\n",
    "            df['open'] = (df['open'] - min_return) / (max_return - min_return)\n",
    "            df['high'] = (df['high'] - min_return) / (max_return - min_return)\n",
    "            df['low'] =  (df['low'] - min_return) / (max_return - min_return)\n",
    "            df['close']= (df['close'] - min_return) / (max_return - min_return)\n",
    "\n",
    "            min_volume = df[(df.index < valid_start)]['volume'].min(axis=0)\n",
    "            max_volume = df[(df.index < valid_start)]['volume'].max(axis=0)\n",
    "\n",
    "            df['volume'] = (df['volume'] - min_volume) / (max_volume - min_volume)\n",
    "\n",
    "            # - Partition the data frame into train/valid/test -\n",
    "            df.drop(columns=['date'], inplace=True)\n",
    "            df_train = df[(df.index < valid_start)]\n",
    "            df_val = df[(df.index >= valid_start) & (df.index < test_start)]\n",
    "            df_test = df[(df.index >= test_start)]\n",
    "\n",
    "            c_train_data = df_train.values\n",
    "            c_val_data = df_val.values\n",
    "            c_test_data = df_test.values\n",
    "            \n",
    "            # -Add the data frame data to the train/valid/test-\n",
    "            for i in range(stock_history_length, len(c_train_data), time_step):\n",
    "                train_data.append(c_train_data[i-stock_history_length:i][None])\n",
    "                train_labels.append(c_train_data[i, 3][None])\n",
    "            for i in range(stock_history_length, len(c_val_data), time_step):\n",
    "                val_data.append(c_val_data[i-stock_history_length:i][None])\n",
    "                val_labels.append(c_val_data[i, 3][None])\n",
    "            for i in range(stock_history_length, len(c_test_data), time_step):\n",
    "                test_data.append(c_test_data[i-stock_history_length:i][None])\n",
    "                test_labels.append(c_test_data[i, 3][None])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents of the train, valid and test files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5v55Kay0W327",
    "outputId": "9747441d-f72d-449f-a9d3-43fafa70500a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=train_data.hdf5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/data (EArray(12573778, 128, 5)shuffle, blosc(5)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (204, 128, 5)\n",
       "/labels (EArray(12573778,)shuffle, blosc(5)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (16384,)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O4HLgWYDXIWM",
    "outputId": "07c61054-2438-4143-c899-61c194ce1dca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=val_data.hdf5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/data (EArray(3204370, 128, 5)shuffle, blosc(5)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (204, 128, 5)\n",
       "/labels (EArray(3204370,)shuffle, blosc(5)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (16384,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyk4CuCAXKTr",
    "outputId": "3dbd1e33-5464-44d5-d584-85faf3295f8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "File(filename=test_data.hdf5, title='', mode='w', root_uep='/', filters=Filters(complevel=0, shuffle=False, bitshuffle=False, fletcher32=False, least_significant_digit=None))\n",
       "/ (RootGroup) ''\n",
       "/data (EArray(1328977, 128, 5)shuffle, blosc(5)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (204, 128, 5)\n",
       "/labels (EArray(1328977,)shuffle, blosc(5)) ''\n",
       "  atom := Float64Atom(shape=(), dflt=0.0)\n",
       "  maindim := 0\n",
       "  flavor := 'numpy'\n",
       "  byteorder := 'little'\n",
       "  chunkshape := (8192,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the shape of the data and labels for our sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7Q3J8O9GH1Zv"
   },
   "outputs": [],
   "source": [
    "train_file.close()\n",
    "val_file.close()\n",
    "test_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOaTZ0aHXU3u"
   },
   "outputs": [],
   "source": [
    "# reopen in read mode\n",
    "train_file = tables.open_file(\"train_data.hdf5\", mode='r')\n",
    "val_file = tables.open_file(\"val_data.hdf5\", mode='r')\n",
    "test_file = tables.open_file(\"test_data.hdf5\", mode='r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4Al5S-SXj_3",
    "outputId": "22e9528d-7257-4c62-fca4-e0709cc96fe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12573778, 128, 5), (12573778,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file.root.data.shape, train_file.root.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PPOQoF2QX27f",
    "outputId": "f867fed7-5ac9-45c8-baea-e7ebd787a040"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3204370, 128, 5), (3204370,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_file.root.data.shape, val_file.root.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nYyqLrG2YBZK",
    "outputId": "4219179c-196f-4f01-ce49-cb79ffced3c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1328977, 128, 5), (1328977,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file.root.data.shape, test_file.root.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgXaGAFOXd7L"
   },
   "outputs": [],
   "source": [
    "train_file.close()\n",
    "val_file.close()\n",
    "test_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqRb8dfrYnyX"
   },
   "source": [
    "## Zip and upload data to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "008rPMebY711",
    "outputId": "3759be43-9cfe-46ca-bd7f-466acc94a3c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: test_data.hdf5 (deflated 42%)\n",
      "  adding: train_data.hdf5 (deflated 48%)\n",
      "  adding: val_data.hdf5 (deflated 46%)\n"
     ]
    }
   ],
   "source": [
    "if do_moving_avg:\n",
    "    !zip sp_data_orig_m_avg.zip test_data.hdf5 train_data.hdf5 val_data.hdf5\n",
    "else:\n",
    "    !zip sp_data_orig.zip test_data.hdf5 train_data.hdf5 val_data.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4SZKsdkYxXz",
    "outputId": "35a9e996-6ee0-42ae-8110-06995071559e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /amd/\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/amd/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EYWK0OCPZkuR"
   },
   "outputs": [],
   "source": [
    "if do_moving_avg:\n",
    "    !cp sp_data_orig_m_avg.zip /amd/My\\ Drive/CSC413/Data\n",
    "else:   \n",
    "    !cp sp_data_orig.zip /amd/My\\ Drive/CSC413/Data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "transformer_prepros.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
